{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_05_1_Blackjack_Monte_Carlo_ES.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background: linear-gradient(90deg, #17a2b8 0%, #0e5a63 60%, #0a3d44 100%); color: white; padding: 18px 25px; margin-bottom: 20px;\">\n",
        "    <div style=\"display: flex; justify-content: space-between; align-items: baseline;\">\n",
        "        <h1 style=\"font-family: 'Helvetica Neue', sans-serif; font-size: 24px; margin: 0; font-weight: 300;\">\n",
        "            Lab 5-1: Blackjack with Monte Carlo ES\n",
        "        </h1>\n",
        "    </div>\n",
        "    <p style=\"font-size: 13px; margin-top: 6px; margin-bottom: 0; opacity: 0.9;\">\n",
        "        IE 7295 Reinforcement Learning | Sutton and Barto Chapter 5 | 75 minutes\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: white; padding: 15px 20px; margin-bottom: 12px; border-left: 3px solid #17a2b8;\">\n",
        "    <h3 style=\"color: #17a2b8; font-size: 14px; margin: 0 0 8px 0;\">Background</h3>\n",
        "    <p style=\"color: #555; line-height: 1.6; margin: 0; font-size: 13px;\">\n",
        "        This lab implements Monte Carlo ES exactly as described in the textbook Figure 5.2. \n",
        "        The key insight is Exploring Starts: each episode begins with a random state-action pair, \n",
        "        ensuring all pairs are explored.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<table style=\"width: 100%; border-spacing: 12px;\">\n",
        "<tr>\n",
        "<td style=\"background: white; padding: 12px 15px; border-top: 3px solid #17a2b8; width: 50%;\">\n",
        "    <h4 style=\"color: #17a2b8; font-size: 13px; margin: 0 0 8px 0;\">Learning Objectives</h4>\n",
        "    <ul style=\"color: #555; line-height: 1.4; margin: 0; padding-left: 18px; font-size: 12px;\">\n",
        "        <li>Implement Monte Carlo ES algorithm</li>\n",
        "        <li>Understand exploring starts mechanism</li>\n",
        "        <li>Learn optimal Blackjack policy</li>\n",
        "        <li>Reproduce textbook results</li>\n",
        "    </ul>\n",
        "</td>\n",
        "<td style=\"background: white; padding: 12px 15px; border-top: 3px solid #00acc1; width: 50%;\">\n",
        "    <h4 style=\"color: #00acc1; font-size: 13px; margin: 0 0 8px 0;\">Blackjack Rules</h4>\n",
        "    <div style=\"color: #555; font-size: 12px; line-height: 1.6;\">\n",
        "        <div>Actions: 0=Stick, 1=Hit</div>\n",
        "        <div>States: (sum, dealer, ace)</div>\n",
        "        <div>Rewards: +1, 0, -1</div>\n",
        "    </div>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "<div style=\"border-left: 4px solid #17a2b8; padding-left: 12px; margin: 20px 0;\">\n",
        "  <h2 style=\"color: #17a2b8; margin: 0; font-size: 18px;\">Section 1: Environment Setup</h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "try:\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/mdehghani86/RL_labs/master/utility/rl_utility.py'\n",
        "    exec(requests.get(url).text)\n",
        "    pretty_print(\"Environment Ready\", \n",
        "                 \"Implementing MC ES from Figure 5.2\", \n",
        "                 style='success')\n",
        "except:\n",
        "    print(\"Libraries loaded\")\n",
        "\n",
        "env = gym.make('Blackjack-v1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "<div style=\"border-left: 4px solid #17a2b8; padding-left: 12px; margin: 20px 0;\">\n",
        "  <h2 style=\"color: #17a2b8; margin: 0; font-size: 18px;\">Section 2: Monte Carlo ES Algorithm</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"text-align: center; margin: 20px 0;\">\n",
        "    <img src=\"https://github.com/mdehghani86/RL_labs/blob/master/Lab%2005/MCM_ES.jpg?raw=true\" \n",
        "         alt=\"Monte Carlo ES\" \n",
        "         style=\"width: 70%; border: 2px solid #17a2b8; border-radius: 8px;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def generate_episode_es(env, policy):\n",
        "    episode = []\n",
        "    state, _ = env.reset()\n",
        "    \n",
        "    # EXPLORING START: Random first action\n",
        "    action = env.action_space.sample()\n",
        "    next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    episode.append((state, action, reward))\n",
        "    \n",
        "    # Follow greedy policy for rest of episode\n",
        "    state = next_state\n",
        "    while not done:\n",
        "        action = policy.get(state, env.action_space.sample())\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "    \n",
        "    return episode\n",
        "\n",
        "print(\"Episode generation ready\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def monte_carlo_es(env, num_episodes=500000):\n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "    returns = defaultdict(list)\n",
        "    policy = {}\n",
        "    \n",
        "    print(f\"Starting MC ES with {num_episodes:,} episodes...\")\n",
        "    \n",
        "    for ep in range(1, num_episodes + 1):\n",
        "        episode = generate_episode_es(env, policy)\n",
        "        visited = set()\n",
        "        G = 0\n",
        "        \n",
        "        for t in range(len(episode) - 1, -1, -1):\n",
        "            state, action, reward = episode[t]\n",
        "            G = reward + G\n",
        "            sa = (state, action)\n",
        "            \n",
        "            if sa not in visited:\n",
        "                visited.add(sa)\n",
        "                returns[sa].append(G)\n",
        "                Q[state][action] = np.mean(returns[sa])\n",
        "                policy[state] = np.argmax(Q[state])\n",
        "        \n",
        "        if ep % 100000 == 0:\n",
        "            print(f\"Episode {ep:,}\")\n",
        "    \n",
        "    print(\"\\nMC ES complete\")\n",
        "    return Q, policy\n",
        "\n",
        "print(\"MC ES algorithm ready\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "<div style=\"border-left: 4px solid #17a2b8; padding-left: 12px; margin: 20px 0;\">\n",
        "  <h2 style=\"color: #17a2b8; margin: 0; font-size: 18px;\">Section 3: Visualization</h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_value_function(Q):\n",
        "    def get_Z(ps, dc, ua):\n",
        "        s = (ps, dc, ua)\n",
        "        return np.max(Q[s]) if s in Q else 0\n",
        "    \n",
        "    def create_surface(ua, ax):\n",
        "        pr = np.arange(12, 22)\n",
        "        dr = np.arange(1, 11)\n",
        "        X, Y = np.meshgrid(pr, dr)\n",
        "        Z = np.array([[get_Z(x, y, ua) for x in pr] for y in dr])\n",
        "        surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm, vmin=-1, vmax=1, alpha=0.8)\n",
        "        ax.set_xlabel('Player Sum')\n",
        "        ax.set_ylabel('Dealer')\n",
        "        ax.set_zlabel('Value')\n",
        "        ax.set_zlim(-1, 1)\n",
        "        ax.view_init(25, -130)\n",
        "        return surf\n",
        "    \n",
        "    fig = plt.figure(figsize=(14, 10))\n",
        "    ax1 = fig.add_subplot(211, projection='3d')\n",
        "    ax1.set_title('With Usable Ace', fontweight='bold')\n",
        "    surf1 = create_surface(True, ax1)\n",
        "    fig.colorbar(surf1, ax=ax1, shrink=0.5)\n",
        "    \n",
        "    ax2 = fig.add_subplot(212, projection='3d')\n",
        "    ax2.set_title('No Usable Ace', fontweight='bold')\n",
        "    surf2 = create_surface(False, ax2)\n",
        "    fig.colorbar(surf2, ax=ax2, shrink=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_policy(pol):\n",
        "    def get_a(ps, dc, ua):\n",
        "        return pol.get((ps, dc, ua), 1)\n",
        "    \n",
        "    def create_hm(ua, ax):\n",
        "        pr = np.arange(12, 22)\n",
        "        dr = np.arange(1, 11)\n",
        "        Z = np.array([[get_a(p, d, ua) for p in pr] for d in dr])\n",
        "        im = ax.pcolormesh(pr, dr, Z, cmap='RdYlGn_r', edgecolors='black',\n",
        "                          linewidth=0.5, vmin=0, vmax=1, shading='flat')\n",
        "        ax.set_xticks(pr)\n",
        "        ax.set_yticks(dr)\n",
        "        ax.set_yticklabels(['A'] + list(range(2, 11)))\n",
        "        ax.set_xlabel('Player Sum')\n",
        "        ax.set_ylabel('Dealer')\n",
        "        ax.set_aspect('equal')\n",
        "        cbar = plt.colorbar(im, ax=ax, ticks=[0.25, 0.75])\n",
        "        cbar.ax.set_yticklabels(['STICK', 'HIT'])\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    ax1.set_title('With Usable Ace', fontweight='bold')\n",
        "    create_hm(True, ax1)\n",
        "    ax2.set_title('No Usable Ace', fontweight='bold')\n",
        "    create_hm(False, ax2)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Visualization functions ready\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "<div style=\"border-left: 4px solid #17a2b8; padding-left: 12px; margin: 20px 0;\">\n",
        "  <h2 style=\"color: #17a2b8; margin: 0; font-size: 18px;\">Section 4: Run Experiments</h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Q, policy = monte_carlo_es(env, num_episodes=500000)\n",
        "\n",
        "stick = sum(1 for a in policy.values() if a == 0)\n",
        "hit = sum(1 for a in policy.values() if a == 1)\n",
        "total = len(policy)\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"States: {total}\")\n",
        "print(f\"STICK: {stick} ({100*stick/total:.1f}%)\")\n",
        "print(f\"HIT: {hit} ({100*hit/total:.1f}%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Generating visualizations...\")\n",
        "plot_value_function(Q)\n",
        "plot_policy(policy)\n",
        "print(\"Complete - results should match textbook Figure 5.2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background: linear-gradient(90deg, #17a2b8 0%, #0e5a63 60%, #0a3d44 100%); color: white; padding: 15px 20px; margin-top: 30px; text-align: center;\">\n",
        "    <p style=\"margin: 0;\">End of Lab 5-1: Monte Carlo ES</p>\n",
        "</div>"
      ]
    }
  ]
}
